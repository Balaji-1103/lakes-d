import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import ee
import folium
import json
from streamlit_folium import st_folium
from gee_backend import get_gee_data

# ---------------- PAGE CONFIG ----------------
st.set_page_config(
    page_title="Bengaluru Lake Risk Dashboard",
    layout="wide"
)

# ---------------- GEE SETUP & AUTH ----------------
import google.oauth2.service_account as service_account

PROJECT_ID = 'gee-lake-project' 

if "gcp_service_account" in st.secrets:
    key_dict = dict(st.secrets["gcp_service_account"])
    credentials = service_account.Credentials.from_service_account_info(key_dict)
    
    # --- THIS IS THE FIX: DECLARING THE SCOPE ---
    scoped_credentials = credentials.with_scopes(['https://www.googleapis.com/auth/earthengine'])
    ee.Initialize(scoped_credentials, project=PROJECT_ID)
    
else:
    try:
        ee.Initialize(project=PROJECT_ID)
    except Exception as e:
        ee.Authenticate()
        ee.Initialize(project=PROJECT_ID)

# ---------------- DYNAMIC DATA FETCHING ----------------
@st.cache_data(ttl=86400)
def load_gee_data():
    with st.spinner('üì° Fetching satellite data, water quality, and computing ML risk scores...'):
        finalWithRank, yearlyWaterStats, monthlyWaterStats = get_gee_data()
        
        rank_data = finalWithRank.getInfo()['features']
        yearly_data = yearlyWaterStats.getInfo()['features']
        monthly_data = monthlyWaterStats.getInfo()['features']
        
        df_rank = pd.DataFrame([f['properties'] for f in rank_data])
        df_yearly = pd.DataFrame([f['properties'] for f in yearly_data])
        df_monthly = pd.DataFrame([f['properties'] for f in monthly_data])
        
        return df_rank, df_yearly, df_monthly

@st.cache_data(show_spinner=False)
def get_timelapse_url(lake_name):
    """Generates an Earth Engine GIF URL for the selected lake from 2018-2024"""
    lakes_fc = ee.FeatureCollection('projects/gee-lake-project/assets/bengaluru_lakes')
    lake_geom = lakes_fc.filter(ee.Filter.eq('name', lake_name)).geometry()
    
    years = ee.List.sequence(2018, 2024)
    
    def create_yearly_image(year):
        start = ee.Date.fromYMD(year, 1, 1)
        end = start.advance(1, 'year')
        img = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED') \
            .filterBounds(lake_geom) \
            .filterDate(start, end) \
            .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 30)) \
            .median() \
            .visualize(bands=['B4', 'B3', 'B2'], min=0, max=3000) \
            .clip(lake_geom.buffer(500))
        return img
    
    timelapse_col = ee.ImageCollection.fromImages(years.map(create_yearly_image))
    video_args = {
        'dimensions': 600,
        'region': lake_geom.buffer(500).bounds(),
        'framesPerSecond': 1.5,
        'crs': 'EPSG:3857'
    }
    return timelapse_col.getVideoThumbURL(video_args)

st.title("üåä Geo-Intelligence Based Urban Lake Risk Assessment")

# ---------------- LOAD DATA ----------------
rank_df, yearly_df, monthly_df = load_gee_data()

# ---------------- MODEL PERFORMANCE ----------------
st.markdown("## ü§ñ ML Model Performance")
colA, colB = st.columns(2)
colA.metric("Overall Accuracy", "95.74%")
colB.metric("Kappa Score", "0.94")
st.markdown("---")

# ---------------- ALERT FLAG ----------------
rank_df["Alert"] = rank_df["Risk_Score"].apply(lambda x: "YES" if x >= 70 else "NO")

# =========================================================
# SECTION 1: GLOBAL OVERVIEW
# =========================================================

st.markdown("## üìä Risk Overview")
col1, col2, col3 = st.columns(3)

with col1:
    highest = rank_df.sort_values("Rank").iloc[0]["Lake"]
    st.markdown("### üèÜ Highest Priority Lake")
    st.markdown(f"<h2 style='text-align:center;color:red'>{highest}</h2>", unsafe_allow_html=True)

with col2:
    critical_count = len(rank_df[rank_df["Risk_Category"] == "Critical"])
    st.markdown("### üö® Critical Lakes")
    st.markdown(f"<h2 style='text-align:center;color:red'>{critical_count}</h2>", unsafe_allow_html=True)

with col3:
    avg_score = round(rank_df["Risk_Score"].mean(), 2)
    st.markdown("### üìà Average Risk Score")
    st.markdown(f"<h2 style='text-align:center;color:orange'>{avg_score}</h2>", unsafe_allow_html=True)

st.markdown("---")

st.sidebar.header("üîé Filter Options")
risk_filter = st.sidebar.multiselect(
    "Select Risk Category",
    options=rank_df["Risk_Category"].unique(),
    default=rank_df["Risk_Category"].unique()
)
filtered_df = rank_df[rank_df["Risk_Category"].isin(risk_filter)]

col_table, col_heatmap = st.columns(2)
with col_table:
    st.markdown("## üèÖ Lake Priority Ranking")
    st.dataframe(filtered_df.sort_values("Rank"), width="stretch")

with col_heatmap:
    st.markdown("## üö® Risk Score by Lake")
    sorted_df = filtered_df.sort_values("Risk_Score", ascending=True)
    color_map = {"Critical": "red", "High": "orange", "Medium": "gold", "Low": "green"}
    bar_colors = sorted_df["Risk_Category"].map(color_map)

    fig1, ax1 = plt.subplots()
    ax1.barh(sorted_df["Lake"], sorted_df["Risk_Score"], color=bar_colors)
    ax1.set_xlabel("Risk Score")
    ax1.set_ylabel("Lake")
    ax1.grid(axis="x", linestyle="--", alpha=0.3)
    st.pyplot(fig1)

col_donut, col_scatter = st.columns(2)
with col_donut:
    st.markdown("## üìä Risk Category Share")
    risk_counts = rank_df["Risk_Category"].value_counts()
    pie_colors = [color_map.get(cat, "grey") for cat in risk_counts.index]

    fig2, ax2 = plt.subplots()
    ax2.pie(risk_counts, labels=risk_counts.index, autopct="%1.1f%%", colors=pie_colors)
    centre_circle = plt.Circle((0, 0), 0.60, fc='white')
    fig2.gca().add_artist(centre_circle)
    ax2.axis("equal")
    st.pyplot(fig2)

with col_scatter:
    st.markdown("## üèôÔ∏è Encroachment vs Water Stress")
    scatter_colors = filtered_df["Risk_Category"].map(color_map)

    fig3, ax3 = plt.subplots()
    ax3.scatter(filtered_df["Encroachment_Percent"], filtered_df["Water_Stress_Score"], c=scatter_colors, s=120, edgecolors="black", alpha=0.8)
    ax3.set_xlabel("Encroachment (%)")
    ax3.set_ylabel("Water Stress Score")
    ax3.grid(True, linestyle="--", alpha=0.3)

    for i, lake in enumerate(filtered_df["Lake"]):
        ax3.annotate(lake, (filtered_df["Encroachment_Percent"].iloc[i], filtered_df["Water_Stress_Score"].iloc[i]), fontsize=8)
    st.pyplot(fig3)

st.markdown("## üö® Lakes Requiring Immediate Attention")
alert_df = rank_df[rank_df["Risk_Category"].isin(["Critical", "High"])]
st.dataframe(alert_df[["Rank", "Lake", "Risk_Score", "Risk_Category"]], width="stretch")

# =========================================================
# SECTION 2: LAKE DEEP DIVE (SPECIFIC ANALYSIS)
# =========================================================
st.markdown("---")
st.markdown("## üî¨ Deep Dive: Individual Lake Analysis")
selected_lake = st.selectbox("Select a Lake for Detailed Analysis", rank_df["Lake"].unique())
lake_stats = rank_df[rank_df["Lake"] == selected_lake].iloc[0]

# --- NEW: AUTOMATED AI ANALYST ---
st.markdown(f"### ü§ñ AI Executive Summary: {selected_lake}")

# AI Logic Engine
enc = lake_stats['Encroachment_Percent']
enc_str = "severe" if enc >= 40 else "moderate" if enc >= 20 else "low"

algae = lake_stats['Algae_NDCI_Score']
turbidity = lake_stats['Turbidity_NDTI_Score']
wq_str = "poor" if (algae > 60 or turbidity > 60) else "moderate" if (algae > 40 or turbidity > 40) else "relatively healthy"

change = lake_stats['Water_Change_Percent']
change_str = f"shrunk by {abs(change):.1f}%" if change < -5 else f"expanded by {change:.1f}%" if change > 5 else "remained stable"

# Get slope for AI prediction text
lake_trend_ai = yearly_df[yearly_df["Lake"] == selected_lake].sort_values("Year")
x_ai = lake_trend_ai["Year"].values
y_ai = lake_trend_ai["Water_Area_sqkm"].values
slope = 0
if len(x_ai) > 1:
    z_ai = np.polyfit(x_ai, y_ai, 1)
    slope = z_ai[0]
trend_str = "a continued drying trend" if slope < -0.005 else "stable or recovering water levels" if slope > 0.005 else "stagnant conditions"

# Generate the AI Text
ai_summary = f"""
**Insight:** {selected_lake} is currently classified as a **{lake_stats['Risk_Category']} Risk** zone (Score: {lake_stats['Risk_Score']:.1f}/100). 
Spatial ML analysis reveals **{enc_str} urban encroachment ({enc:.1f}%)** within its 500m buffer. Since 2020, the surface water area has **{change_str}**. Ecological remote sensors indicate **{wq_str} water quality** (Algae severity: {algae:.1f}/100, Turbidity: {turbidity:.1f}/100). Based on the 2018-2024 trajectory, predictive models forecast **{trend_str}** heading into 2030 unless interventions are made.
"""

# Render color-coded box based on risk
if lake_stats['Risk_Category'] in ['Critical', 'High']:
    st.error(ai_summary)
elif lake_stats['Risk_Category'] == 'Medium':
    st.warning(ai_summary)
else:
    st.success(ai_summary)


# --- WATER QUALITY METRICS ---
st.markdown(f"### üß™ Water Quality Metrics (2024)")
colQ1, colQ2, colQ3 = st.columns(3)
with colQ1:
    st.metric("Algae Severity (NDCI)", f"{round(lake_stats['Algae_NDCI_Score'], 2)} / 100")
with colQ2:
    st.metric("Turbidity/Pollution (NDTI)", f"{round(lake_stats['Turbidity_NDTI_Score'], 2)} / 100")
with colQ3:
    st.metric("Total Risk Score", f"{round(lake_stats['Risk_Score'], 2)}")

# --- TABBED VIEW: SATELLITE MAP vs TIMELAPSE ---
tab1, tab2 = st.tabs(["üó∫Ô∏è Live Satellite Map", "‚è≥ Animated Timelapse (2018 - 2024)"])

with tab1:
    with st.spinner("Rendering Native Earth Engine Satellite Map..."):
        lakes_fc = ee.FeatureCollection('projects/gee-lake-project/assets/bengaluru_lakes')
        selected_ee_lake = lakes_fc.filter(ee.Filter.eq('name', selected_lake))
        
        bounds = selected_ee_lake.geometry().bounds().getInfo()['coordinates'][0]
        center_lat = sum([c[1] for c in bounds]) / len(bounds)
        center_lon = sum([c[0] for c in bounds]) / len(bounds)
        
        Map = folium.Map(location=[center_lat, center_lon], zoom_start=14)
        
        s2 = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED') \
            .filterBounds(selected_ee_lake.geometry()) \
            .filterDate('2024-01-01', '2024-12-31') \
            .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 30)) \
            .median()
            
        map_id_dict = s2.getMapId({'bands': ['B4', 'B3', 'B2'], 'min': 0, 'max': 3000})
        folium.TileLayer(
            tiles=map_id_dict['tile_fetcher'].url_format,
            attr='Google Earth Engine',
            name='Sentinel-2 RGB (2024)',
            overlay=True,
            control=True
        ).add_to(Map)
        
        folium.GeoJson(
            data=selected_ee_lake.getInfo(),
            name=f'{selected_lake} Boundary',
            style_function=lambda x: {'color': 'red', 'fillColor': 'transparent', 'weight': 2}
        ).add_to(Map)
        
        folium.GeoJson(
            data=selected_ee_lake.geometry().buffer(500).getInfo(),
            name='500m Buffer Zone',
            show=False,
            style_function=lambda x: {'color': 'yellow', 'fillColor': 'transparent', 'weight': 2, 'dashArray': '5, 5'}
        ).add_to(Map)
        
        folium.LayerControl().add_to(Map)
        st_folium(Map, use_container_width=True, height=500, returned_objects=[])

with tab2:
    with st.spinner("Generating Earth Engine Timelapse GIF... (This takes a few seconds)"):
        gif_url = get_timelapse_url(selected_lake)
        st.markdown(f"<h4 style='text-align: center;'>Urban Encroachment & Water Level Changes at {selected_lake}</h4>", unsafe_allow_html=True)
        st.image(gif_url, use_container_width=True)

# --- YEAR VS YEAR COMPARISON ---
st.markdown(f"### üìÖ Year vs Year Water Comparison: {selected_lake}")
available_years = sorted(yearly_df["Year"].unique())
colY1, colY2 = st.columns(2)
year1 = colY1.selectbox("Select Year 1", available_years, index=0)
year2 = colY2.selectbox("Select Year 2", available_years, index=len(available_years)-1)

lake_year_data = yearly_df[(yearly_df["Lake"] == selected_lake) & (yearly_df["Year"].isin([year1, year2]))]

fig4, ax4 = plt.subplots()
ax4.bar(lake_year_data["Year"].astype(str), lake_year_data["Water_Area_sqkm"], color=['#1f77b4', '#ff7f0e'])
ax4.set_ylabel("Water Area (sq.km)")
ax4.grid(axis="y", linestyle="--", alpha=0.3)
st.pyplot(fig4)

# --- PREDICTIVE FORECASTING (YEARLY TREND) ---
st.markdown(f"### üîÆ Predictive Forecast & Yearly Trend: {selected_lake} (2018 - 2030)")
fig5, ax5 = plt.subplots()
ax5.plot(x_ai, y_ai, marker='o', label="Historical Water Area", color='blue')

if len(x_ai) > 1:
    p = np.poly1d(z_ai)
    future_x = np.array([2024, 2025, 2026, 2027, 2028, 2029, 2030])
    future_y = p(future_x)
    ax5.plot(future_x, future_y, linestyle='--', color='red', label="Forecasted Trend (Linear)")

ax5.set_xlabel("Year")
ax5.set_ylabel("Water Area (sq.km)")
ax5.legend()
ax5.grid(True, linestyle="--", alpha=0.4)
st.pyplot(fig5)

# --- MONTHLY TREND ---
st.markdown(f"### üìä Monthly Water Fluctuation: {selected_lake}")
selected_year_monthly = st.selectbox("Select Year for Monthly Trend", available_years, index=len(available_years)-1, key="month_year_select")

monthly_lake = monthly_df[(monthly_df["Lake"] == selected_lake) & (monthly_df["Year"] == selected_year_monthly)]
fig6, ax6 = plt.subplots()
ax6.plot(monthly_lake["Month"], monthly_lake["Water_Area_sqkm"], marker='s', color='teal')
ax6.set_xlabel("Month")
ax6.set_ylabel("Water Area (sq.km)")
ax6.set_xticks(range(1, 13))
ax6.grid(True, linestyle="--", alpha=0.4)
st.pyplot(fig6)

# ---------------- FOOTER ----------------
st.markdown("---")
st.markdown("<center>Developed by Balaji | Geo-Intelligence Lake Risk System | 2026</center>", unsafe_allow_html=True)